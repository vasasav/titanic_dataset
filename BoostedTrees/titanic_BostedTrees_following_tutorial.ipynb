{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic and boosted trees\n",
    "\n",
    "Following https://www.tensorflow.org/tutorials/estimator/boosted_trees. Will then try to do it differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import IPython.display as ipyd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import typing as tp\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and define schema (feature columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 627 (70.4%) of the full number of records\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DF = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "EVAL_DF = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "\n",
    "total_count = len(TRAIN_DF) + len(EVAL_DF)\n",
    "\n",
    "print(f'Train size = {len(TRAIN_DF)} ({100*len(TRAIN_DF)/total_count:.1f}%) of the full number of records')\n",
    "\n",
    "LABEL_NAME = 'survived'\n",
    "TRAIN_LABEL = TRAIN_DF.pop(LABEL_NAME)\n",
    "#\n",
    "EVAL_LABEL = EVAL_DF.pop(LABEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\n",
    "    'sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone'\n",
    "]\n",
    "#\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "#######\n",
    "\n",
    "def one_hot_cat_column(\n",
    "    feature_name: str, \n",
    "    vocab_list: tp.List[tp.Union[str, int]]\n",
    ")->tf.feature_column.indicator_column:\n",
    "    \"\"\"\n",
    "    Given the name of the categorical feature and its vocabulary use one-hot\n",
    "    encoding to convert this feature to indicator_column\n",
    "    \"\"\"\n",
    "    \n",
    "    # basic wrapper for one-hot encoded column\n",
    "    cat_feat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature_name,\n",
    "        vocabulary_list=vocab_list\n",
    "    )\n",
    "    \n",
    "    # multi-hot representation. not quite sure why this extra layer is needed\n",
    "    return tf.feature_column.indicator_column(cat_feat_col)\n",
    "\n",
    "#######\n",
    "\n",
    "FEATURE_COLUMNS = [] # list of feature columns, essentially schema\n",
    "\n",
    "# add categorical columns\n",
    "for fn in CATEGORICAL_COLUMNS:\n",
    "    cur_vocab = TRAIN_DF[fn].unique()\n",
    "    FEATURE_COLUMNS.append(one_hot_cat_column(fn, cur_vocab))\n",
    "    \n",
    "# add numeric columns\n",
    "for fn in NUMERIC_COLUMNS:\n",
    "    FEATURE_COLUMNS.append(tf.feature_column.numeric_column(fn, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion\n",
    "\n",
    "Suitable for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = len(TRAIN_LABEL)\n",
    "\n",
    "#######\n",
    "\n",
    "def make_input_fn(\n",
    "    features_df:  pd.DataFrame,\n",
    "    labels_srs:   pd.Series,\n",
    "    epoch_count:  tp.Optional[int]=None,\n",
    "    shuffle:      tp.Optional[bool]=True,\n",
    "    num_examples: tp.Optional[int]=NUM_EXAMPLES\n",
    "    #\n",
    ")->tp.Callable[[], tf.data.Dataset]:\n",
    "    ###\n",
    "    def input_fn()->tf.data.Dataset:\n",
    "        # dict(TRAIN_DF) essentially converts dataframe into {column_name: column-value-list} dictonary\n",
    "        # createing dataset like this means that the basic records of the dataset will \n",
    "        # be tuples of: (<feature values>, <label_value>)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices( (dict(TRAIN_DF), TRAIN_LABEL) )\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=num_examples)\n",
    "            \n",
    "        # setting epochs to none will keep to indefinte cycling\n",
    "        # setting to 1 will lead to going over data once\n",
    "        # former is better for training, latter for eval/test\n",
    "        dataset = dataset.repeat(count=epoch_count)\n",
    "            \n",
    "        # batch data to have multiple rows included as one\n",
    "        # in the dataset\n",
    "        dataset = dataset.batch(num_examples)\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    ###\n",
    "    \n",
    "    return input_fn\n",
    "    \n",
    "# prepare training and eval data functions\n",
    "TRAIN_INPUT_FN = make_input_fn(TRAIN_DF, TRAIN_LABEL)\n",
    "EVAL_INPUT_FN = make_input_fn(EVAL_DF, EVAL_LABEL, shuffle=False, epoch_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpx4hmmmt4\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpx4hmmmt4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/cryo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:398: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/cryo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpx4hmmmt4/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931475, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 153.271\n",
      "INFO:tensorflow:loss = 0.2141528, step = 99 (0.653 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpx4hmmmt4/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n",
      "INFO:tensorflow:Loss for final step: 0.2141528.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/cryo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:642: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-22T00:32:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpx4hmmmt4/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.34418s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-22-00:32:19\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.93939394, accuracy_baseline = 0.6124402, auc = 0.97687864, auc_precision_recall = 0.9722654, average_loss = 0.21375903, global_step = 100, label/mean = 0.3875598, loss = 0.21375903, precision = 0.95555556, prediction/mean = 0.38759565, recall = 0.8847737\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpx4hmmmt4/model.ckpt-100\n"
     ]
    }
   ],
   "source": [
    "N_BATCHES = 1 \n",
    "BT_EST = tf.estimator.BoostedTreesClassifier(FEATURE_COLUMNS, n_batches_per_layer=N_BATCHES)\n",
    "\n",
    "# train\n",
    "BT_EST.train(TRAIN_INPUT_FN, max_steps=100)\n",
    "\n",
    "# evaluate result\n",
    "BT_RESULT = BT_EST.evaluate(EVAL_INPUT_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.93939394, 'accuracy_baseline': 0.6124402, 'auc': 0.97687864, 'auc_precision_recall': 0.9722654, 'average_loss': 0.21375903, 'label/mean': 0.3875598, 'loss': 0.21375903, 'precision': 0.95555556, 'prediction/mean': 0.38759562, 'recall': 0.8847737, 'global_step': 100}\n"
     ]
    }
   ],
   "source": [
    "print(BT_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Trees Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1710.11555\n",
    "https://medium.com/tensorflow/how-to-train-boosted-trees-models-in-tensorflow-ca8466a53127\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
