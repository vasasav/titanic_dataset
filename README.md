# titanic_dataset

Trying models on titanic dataset.

## Directory `prelims`

Downloading the initial dataset, exploring it, and preparing it for machine learning.

## Directory `XGBoost`

Once data has been explored and packaged as pickle files, applying the XGBoost classifier. Exploring feature importance and hyper-parameter tuning

## Directory `BoostedTrees`

Applying tensorflow's BoostedTrees model to titanic dataset. Checking saving/loading model. Global feature importance. Some work on checking the model graphs
